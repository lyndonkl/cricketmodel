{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": [],
   "gpuType": "T4"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  },
  "accelerator": "GPU"
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cricket GNN Hyperparameter Search on Colab\n",
    "\n",
    "This notebook runs hyperparameter optimization for the Cricket Ball Prediction GNN model using a free T4 GPU on Google Colab.\n",
    "\n",
    "**Prerequisites:**\n",
    "- Google account\n",
    "- WandB account (free at wandb.ai)\n",
    "- `data/t20s_male_json.zip` file (216 MB)\n",
    "\n",
    "**Important:** Colab sessions have a 12-hour limit. Save your results frequently!\n",
    "\n",
    "For detailed instructions, see `notes/training-guides/colab-guide.md`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. GPU Check & Setup\n",
    "\n",
    "First, verify that a GPU is available. You should see a T4 GPU listed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify GPU is available\n",
    "!nvidia-smi\n",
    "\n",
    "import torch\n",
    "print(f\"\\nCUDA available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB\")\n",
    "else:\n",
    "    print(\"\\n** WARNING: No GPU detected! **\")\n",
    "    print(\"Go to Runtime > Change runtime type > Hardware accelerator > T4 GPU\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Clone Repository\n",
    "\n",
    "Clone the Cricket GNN repository from GitHub."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!git clone https://github.com/lyndonkl/cricketmodel.git\n",
    "%cd cricketmodel\n",
    "!git log --oneline -3  # Show recent commits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Install Dependencies\n",
    "\n",
    "Install PyTorch Geometric and other required packages. This may take a few minutes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install torch-geometric and dependencies\n",
    "!pip install torch-geometric\n",
    "\n",
    "# Install Optuna and WandB for hyperparameter search\n",
    "!pip install optuna optuna-integration[wandb] wandb\n",
    "\n",
    "# Install other dependencies\n",
    "!pip install tqdm pyyaml scikit-learn plotly\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"Dependencies installed successfully!\")\n",
    "print(\"=\"*50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. WandB Login\n",
    "\n",
    "Login to Weights & Biases for experiment tracking. You'll need your API key from [wandb.ai/authorize](https://wandb.ai/authorize)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb\n",
    "\n",
    "# This will prompt you to enter your API key\n",
    "# Get it from: https://wandb.ai/authorize\n",
    "wandb.login()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Upload & Extract Raw Data\n",
    "\n",
    "Upload the `t20s_male_json.zip` file (216 MB). When you run this cell, a file upload dialog will appear.\n",
    "\n",
    "**Note:** The upload may take a few minutes depending on your internet connection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import files\n",
    "import os\n",
    "\n",
    "# Upload t20s_male_json.zip when prompted\n",
    "print(\"Please upload 't20s_male_json.zip' (216 MB)...\")\n",
    "uploaded = files.upload()\n",
    "\n",
    "# Check what was uploaded\n",
    "for filename in uploaded.keys():\n",
    "    print(f\"Uploaded: {filename} ({len(uploaded[filename]) / 1e6:.1f} MB)\")\n",
    "\n",
    "# Extract to data directory\n",
    "!mkdir -p data\n",
    "!unzip -q t20s_male_json.zip -d data/\n",
    "\n",
    "# Verify extraction\n",
    "json_count = len([f for f in os.listdir('data/t20s_male_json') if f.endswith('.json')])\n",
    "print(f\"\\nExtracted {json_count} JSON match files to data/t20s_male_json/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Process Data (One-Time, ~30 min)\n",
    "\n",
    "This cell processes the raw JSON data into PyTorch graphs. **This only needs to run once per session** - the processed data is cached.\n",
    "\n",
    "**Expected time:** ~30 minutes on first run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "print(\"Processing data - this takes ~30 minutes on first run...\")\n",
    "print(\"The data will be cached for the rest of this session.\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "# Run minimal HP search to trigger data processing\n",
    "!python scripts/hp_search.py --phase phase1_coarse --n-trials 1 --epochs 1 --device cuda\n",
    "\n",
    "elapsed = time.time() - start_time\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(f\"Data processing complete! ({elapsed/60:.1f} minutes)\")\n",
    "print(\"=\"*50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Run HP Search\n",
    "\n",
    "Now run the actual hyperparameter search. Adjust `--n-trials` and `--epochs` based on your time budget.\n",
    "\n",
    "**Recommended settings:**\n",
    "- Quick test: `--n-trials 5 --epochs 10` (~30 min)\n",
    "- Standard: `--n-trials 10 --epochs 25` (~2-3 hours)\n",
    "- Thorough: `--n-trials 20 --epochs 30` (~5-6 hours)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Phase 1: Coarse search (GPU-accelerated)\n",
    "# Adjust --n-trials and --epochs based on your time budget\n",
    "\n",
    "!python scripts/hp_search.py \\\n",
    "    --phase phase1_coarse \\\n",
    "    --n-trials 10 \\\n",
    "    --epochs 25 \\\n",
    "    --wandb \\\n",
    "    --device cuda \\\n",
    "    --n-jobs 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. View Results\n",
    "\n",
    "Display the best hyperparameters found during the search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import glob\n",
    "\n",
    "# Find the most recent best_params.json\n",
    "param_files = glob.glob('checkpoints/optuna/cricket_gnn_phase1_coarse_*/best_params.json')\n",
    "\n",
    "if param_files:\n",
    "    # Get most recent file\n",
    "    latest_file = max(param_files, key=os.path.getmtime)\n",
    "    print(f\"Results from: {latest_file}\")\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "    with open(latest_file) as f:\n",
    "        best_params = json.load(f)\n",
    "    \n",
    "    for key, value in best_params.items():\n",
    "        print(f\"{key}: {value}\")\n",
    "else:\n",
    "    print(\"No results found yet. Run the HP search first.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Download Results\n",
    "\n",
    "Download all checkpoints and results to your local machine for further analysis or to continue training later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import files\n",
    "import os\n",
    "\n",
    "# Create results archive\n",
    "!zip -r results.zip checkpoints/optuna/ optuna_studies.db\n",
    "\n",
    "# Show archive contents\n",
    "!unzip -l results.zip | head -20\n",
    "print(\"...\")\n",
    "\n",
    "# Get file size\n",
    "size_mb = os.path.getsize('results.zip') / 1e6\n",
    "print(f\"\\nTotal archive size: {size_mb:.1f} MB\")\n",
    "\n",
    "# Download\n",
    "print(\"\\nStarting download...\")\n",
    "files.download('results.zip')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optional: Continue with Phase 2\n",
    "\n",
    "If you have time remaining in your Colab session, continue to Phase 2 (architecture tuning)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "\n",
    "# Find Phase 1 results\n",
    "phase1_files = glob.glob('checkpoints/optuna/cricket_gnn_phase1_coarse_*/best_params.json')\n",
    "\n",
    "if phase1_files:\n",
    "    latest_phase1 = max(phase1_files, key=os.path.getmtime)\n",
    "    print(f\"Using Phase 1 results from: {latest_phase1}\")\n",
    "    \n",
    "    # Run Phase 2\n",
    "    !python scripts/hp_search.py \\\n",
    "        --phase phase2_architecture \\\n",
    "        --n-trials 12 \\\n",
    "        --epochs 25 \\\n",
    "        --best-params \"{latest_phase1}\" \\\n",
    "        --wandb \\\n",
    "        --device cuda \\\n",
    "        --n-jobs 1\n",
    "else:\n",
    "    print(\"No Phase 1 results found. Run Phase 1 first.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Troubleshooting\n",
    "\n",
    "**GPU not detected:**\n",
    "- Go to Runtime > Change runtime type > Hardware accelerator > T4 GPU\n",
    "\n",
    "**Out of memory:**\n",
    "- Reduce batch size: add `--batch-size 32` to the hp_search command\n",
    "- Restart runtime: Runtime > Restart runtime\n",
    "\n",
    "**Session disconnected:**\n",
    "- Re-run cells 1-5 (GPU check through data upload)\n",
    "- Cell 6 (data processing) will use cached data if available\n",
    "- Your Optuna study is saved to SQLite and can be resumed\n",
    "\n",
    "**WandB errors:**\n",
    "- Run `wandb.login()` again if your session expired"
   ]
  }
 ]
}
